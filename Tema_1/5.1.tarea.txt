Tarea: Mejoras adicionales: LCEL, Prompt Templates, Streaming...
ğŸ“‹ Objetivo

En esta tarea transformarÃ¡s tu chatbot bÃ¡sico en una aplicaciÃ³n mÃ¡s robusta y profesional. AprenderÃ¡s a implementar funcionalidades como configuraciÃ³n dinÃ¡mica, templates de prompts, streaming de respuestas y mejor manejo de errores.

âš ï¸ Importante: Esta tarea contiene conceptos avanzados y es completamente normal que no puedas completar todos los puntos en tu primer intento. No te preocupes si encuentras dificultades, el objetivo es que explores, experimentes y aprendas el proceso. La soluciÃ³n completa estÃ¡ disponible en la siguiente clase del curso para que puedas consultar y comparar tu progreso. Â¡Haz lo que puedas y disfruta el proceso de aprendizaje!



ğŸ¯ Lo que aprenderÃ¡s

PromptTemplate: CÃ³mo crear prompts estructurados y reutilizables

LCEL (LangChain Expression Language): El nuevo paradigma de cadenas en LangChain

Streaming: Respuestas en tiempo real para mejor experiencia de usuario

ConfiguraciÃ³n dinÃ¡mica: Permitir al usuario ajustar parÃ¡metros del modelo

Manejo de errores: Hacer tu aplicaciÃ³n mÃ¡s robusta



ğŸ Punto de partida

Tu cÃ³digo actual deberÃ­a verse similar al siguiente:

from langchain_openai import ChatOpenAI
from langchain_core.messages import AIMessage, HumanMessage, SystemMessage
import streamlit as st
 
# Configurar la pÃ¡gina de la app
st.set_page_config(page_title="Chatbot BÃ¡sico", page_icon="ğŸ¤–")
st.title("ğŸ¤– Chatbot BÃ¡sico con LangChain")
st.markdown("Este es un *chatbot de ejemplo* construido con LangChain + Streamlit. Â¡Escribe tu mensaje abajo para comenzar!")
 
chat_model = ChatOpenAI(model="gpt-4o-mini", temperature=0.5)
 
# Inicializar el historial de mensajes
if "mensajes" not in st.session_state:
    st.session_state.mensajes = []
 
# Mostrar mensajes previos en la interfaz
for msg in st.session_state.mensajes:
    if isinstance(msg, SystemMessage):
        # No muestro el mensaje por pantalla
        continue
    
    role = "assistant" if isinstance(msg, AIMessage) else "user"
    with st.chat_message(role):
        st.markdown(msg.content)
 
# Cuadro de entrada de texto de usuario
pregunta = st.chat_input("Escribe tu mensaje: ")
 
if pregunta:
    # Mostrar inmediatamente el mensaje del usuario en la interfaz
    with st.chat_message("user"):
        st.markdown(pregunta)
    
    # Almacenamos el mensaje en la memoria de streamlit
    st.session_state.mensajes.append(HumanMessage(content=pregunta))
    
    # Generar respuesta usando el modelo de lenguaje
    respuesta = chat_model.invoke(st.session_state.mensajes)
    
    # Mostrar la respuesta en la interfaz
    with st.chat_message("assistant"):
        st.markdown(respuesta.content)
    
    st.session_state.mensajes.append(respuesta)


ğŸ› ï¸ Mejoras a implementar

1. Sidebar de ConfiguraciÃ³n

Objetivo: Permitir al usuario ajustar la temperatura y seleccionar el modelo.

Pista: Usa st.sidebar para crear una barra lateral. Dentro de ella:

with st.sidebar:
    st.header("ConfiguraciÃ³n")
    temperature = st.slider("Temperatura", 0.0, 1.0, 0.5, 0.1)
    model_name = st.selectbox("Modelo", ["gpt-3.5-turbo", "gpt-4", "gpt-4o-mini"])
    
    # Â¿CÃ³mo recrearÃ­as el modelo con los nuevos parÃ¡metros?
    chat_model = # Â¡Completa aquÃ­!


Pregunta reflexiva: Â¿Por quÃ© es Ãºtil recrear el modelo cada vez que cambian los parÃ¡metros?



2. Implementando PromptTemplate

Objetivo: Crear un template estructurado que incluya el historial de conversaciÃ³n.

ImportaciÃ³n necesaria:

from langchain_core.prompts import PromptTemplate

Tu turno: Crea un PromptTemplate que:

Tenga variables mensaje e historial

Defina la personalidad del chatbot

Use el historial para mantener contexto

prompt_template = PromptTemplate(
    input_variables=["mensaje", "historial"],
    template="""Eres un asistente Ãºtil y amigable llamado ChatBot Pro. 
 
Historial de conversaciÃ³n:
{historial}
 
Responde de manera clara y concisa a la siguiente pregunta: {mensaje}"""
)


3. LCEL - LangChain Expression Language

Objetivo: Usar el nuevo paradigma de cadenas con el operador |.

Concepto clave: LCEL permite encadenar componentes de forma intuitiva:

# En lugar de usar cadenas tradicionales, ahora puedes hacer:
cadena = prompt_template | chat_model


Â¿QuÃ© hace esto?: El operador | conecta el output del PromptTemplate directamente al input del ChatModel.



4. Streaming de Respuestas

Objetivo: Mostrar la respuesta del modelo palabra por palabra, como ChatGPT.

ImplementaciÃ³n sugerida:

if pregunta:
    with st.chat_message("user"):
        st.markdown(pregunta)
    
    try:
        with st.chat_message("assistant"):
            response_placeholder = st.empty()
            full_response = ""
 
            # Â¡AquÃ­ estÃ¡ la magia del streaming!
            for chunk in cadena.stream({"mensaje": pregunta, "historial": st.session_state.mensajes}):
                full_response += chunk.content
                response_placeholder.markdown(full_response + "â–Œ")  # El cursor parpadeante
            
            response_placeholder.markdown(full_response)
        
        # No olvides almacenar los mensajes
        st.session_state.mensajes.append(HumanMessage(content=pregunta))
        st.session_state.mensajes.append(AIMessage(content=full_response))
        
    except Exception as e:
        # Â¿QuÃ© tipo de errores podrÃ­an ocurrir aquÃ­?
        st.error(f"Error al generar respuesta: {str(e)}")
        st.info("Verifica que tu API Key de OpenAI estÃ© configurada correctamente.")


Pregunta: Â¿QuÃ© representa el sÃ­mbolo "â–Œ" en el cÃ³digo anterior?



5. BotÃ³n de Nueva ConversaciÃ³n

Objetivo: Permitir al usuario limpiar el historial fÃ¡cilmente.

Pista simple:

if st.button("ğŸ—‘ï¸ Nueva conversaciÃ³n"):
    # Â¿QuÃ© necesitas limpiar?
    # Â¿QuÃ© funciÃ³n de Streamlit refresca la pÃ¡gina?


ğŸ’¡ Reflexiones Finales

Â¿QuÃ© ventajas tiene usar PromptTemplate vs. strings simples?

Â¿CÃ³mo mejora LCEL la legibilidad del cÃ³digo?

Â¿Por quÃ© el streaming mejora la experiencia de usuario?

Â¿QuÃ© otros errores podrÃ­as manejar en una aplicaciÃ³n real?



Â¡DiviÃ©rtete construyendo y no dudes en experimentar con las funcionalidades! ğŸš€